{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0BBPxheouzE"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKI_5lbiouzF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset, filter_agents_by_frames\n",
    "from l5kit.dataset import EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "\n",
    "from l5kit.cle.closed_loop_evaluator import ClosedLoopEvaluator, EvaluationPlan\n",
    "from l5kit.cle.metrics import (CollisionFrontMetric, CollisionRearMetric, CollisionSideMetric,\n",
    "                               DisplacementErrorL2Metric, DistanceToRefTrajectoryMetric)\n",
    "from l5kit.cle.validators import RangeValidator, ValidationCountingAggregator\n",
    "from l5kit.simulation.dataset import SimulationConfig\n",
    "from l5kit.simulation.unroll import ClosedLoopSimulator\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from l5kit.visualization.visualizer.zarr_utils import simulation_out_to_visualizer_scene\n",
    "from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.data import MapAPI\n",
    "\n",
    "from ego_agent import EgoAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtLmUJ1CouzF"
   },
   "source": [
    "## Prepare data path and load cfg\n",
    "\n",
    "By setting the `L5KIT_DATA_FOLDER` variable, we can point the script to the folder where the data lies.\n",
    "\n",
    "Then, we load our config file with relative paths and other configurations (rasteriser, training params...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_XeBMM3oouzG"
   },
   "outputs": [],
   "source": [
    "#@title Download L5 Sample Dataset and install L5Kit\n",
    "import os\n",
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    !wget https://raw.githubusercontent.com/lyft/l5kit/master/examples/setup_notebook_colab.sh -q\n",
    "    !sh ./setup_notebook_colab.sh\n",
    "    os.environ[\"L5KIT_DATA_FOLDER\"] = open(\"./dataset_dir.txt\", \"r\").read().strip()\n",
    "else:\n",
    "    print(\"Not running in Google Colab.\")\n",
    "    os.environ[\"L5KIT_DATA_FOLDER\"] = \"./tmp/l5kit_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZI29omqouzG"
   },
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i2TgS2douzH"
   },
   "source": [
    "## Load the model\n",
    "\n",
    "We load here two models:\n",
    "- the `simulation_model.pt` will be used to control the agents around the SDV;\n",
    "- the `ego_model.pt` will be used to control the SDV itself;\n",
    "\n",
    "Clearly, nothing prevents us from replacing one model with the other (or with a completely different one, provided the input and output stay the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcEdI_WWouzH"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "simulation_model_path = \"./tmp/simulation_model.pt\"\n",
    "simulation_model = torch.load(simulation_model_path).to(device)\n",
    "simulation_model = simulation_model.eval()\n",
    "\n",
    "ego_model_path = \"./tmp/planning_model.pt\"\n",
    "ego_model = EgoAgent()\n",
    "ego_model = ego_model.eval()\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9mfiTF4ouzH"
   },
   "source": [
    "## Load the evaluation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCwROryUouzI"
   },
   "outputs": [],
   "source": [
    "# ===== INIT DATASET\n",
    "eval_cfg = cfg[\"val_data_loader\"]\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "mapAPI = MapAPI.from_cfg(dm ,cfg)\n",
    "eval_zarr = ChunkedDataset(dm.require(eval_cfg[\"key\"])).open()\n",
    "eval_dataset = EgoDataset(cfg, eval_zarr, rasterizer)\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImXyrGpUouzI"
   },
   "source": [
    "## Define some simulation properties\n",
    "We define here some common simulation properties such as the length of the simulation and how many scene to simulate.\n",
    "\n",
    "**NOTE: these properties have a significant impact on the execution time. We suggest you to increase them only if your setup includes a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1w1j-CdouzJ"
   },
   "outputs": [],
   "source": [
    "scenes_to_unroll = [0, 10, 20]\n",
    "num_simulation_step_example1 = 20\n",
    "num_simulation_step_example2 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pCdkKN3ouzL"
   },
   "source": [
    "# Measuring ego metrics with simulated agents\n",
    "The second set of metric we're interested in answer to the question _\"are simulated agents helpful when evaluating SDV?\"_\n",
    "\n",
    "To this end, we can run a simulation with the following features:\n",
    "- both agents and the SDV are simulated (so we can measure interactions between them);\n",
    "- only agents close to the SDV are simulated (this is the only set we really care about in terms of interaction with the SDV);\n",
    "- the set of simulated agents is variable and depends on the proximity of SDV (as the SDV moves in the scene, the agents proximity changes).\n",
    "\n",
    "**Quantitatively**, we can measure how these agents affect the closed-loop metrics for the SDV by comparing the results with those from the log-replayed agents.\n",
    "\n",
    "**Qualitatively**, we can inspect the resulting simulation overlayed with the original trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3LTCMDhouzL"
   },
   "source": [
    "# Quantitative evaluation\n",
    "\n",
    "We define here which metrics are of interest and how to evaluate each one of them. These metrics applies to the SDV only and are the same used in the [closed-loop planning notebook](../planning/closed_loop_test.ipynb).\n",
    "\n",
    "If you want to know more about how each component (metrics, validators, aggregators) of the evaluation stack works, please refer to the source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mB8wdaaouzL"
   },
   "outputs": [],
   "source": [
    "metrics = [DisplacementErrorL2Metric(),\n",
    "           DistanceToRefTrajectoryMetric(),\n",
    "           CollisionFrontMetric(),\n",
    "           CollisionRearMetric(),\n",
    "           CollisionSideMetric()]\n",
    "\n",
    "validators = [RangeValidator(\"displacement_error_l2_validator\", DisplacementErrorL2Metric, max_value=30),\n",
    "              RangeValidator(\"distance_ref_trajectory_validator\", DistanceToRefTrajectoryMetric, max_value=4),\n",
    "              RangeValidator(\"collision_front_validator\", CollisionFrontMetric, max_value=0),\n",
    "              RangeValidator(\"collision_rear_validator\", CollisionRearMetric, max_value=0),\n",
    "              RangeValidator(\"collision_side_validator\", CollisionSideMetric, max_value=0),\n",
    "              ]\n",
    "\n",
    "intervention_validators = [\"displacement_error_l2_validator\",\n",
    "                           \"distance_ref_trajectory_validator\",\n",
    "                           \"collision_front_validator\",\n",
    "                           \"collision_rear_validator\",\n",
    "                           \"collision_side_validator\"]\n",
    "\n",
    "cle_evaluator = ClosedLoopEvaluator(EvaluationPlan(metrics=metrics,\n",
    "                                    validators=validators,\n",
    "                                    composite_metrics=[],\n",
    "                                    intervention_validators=intervention_validators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ6dzLiJouzM"
   },
   "source": [
    "### Evaluating with simulated agents\n",
    "In this evaluation **both the models for planning and simulation are enabled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6ru6ePJcouzM"
   },
   "outputs": [],
   "source": [
    "sim_cfg = SimulationConfig(use_ego_gt=False, use_agents_gt=False, disable_new_agents=False,\n",
    "                           distance_th_far=30, distance_th_close=15, num_simulation_steps=num_simulation_step_example2,\n",
    "                           start_frame_index=0, show_info=True)\n",
    "\n",
    "sim_loop = ClosedLoopSimulator(sim_cfg, eval_dataset, device, model_ego=ego_model, model_agents=simulation_model)\n",
    "\n",
    "sim_outs = sim_loop.unroll(scenes_to_unroll)\n",
    "\n",
    "cle_evaluator.evaluate(sim_outs)\n",
    "validation_results = cle_evaluator.validation_results()\n",
    "agg = ValidationCountingAggregator().aggregate(validation_results)\n",
    "cle_evaluator.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNWNhH2LouzN"
   },
   "source": [
    "# Qualitative evaluation\n",
    "Similarly to the previous example, also here we can show an interactive plot of the simulated scene. Because also the SDV is controlled now, its trajectory are shown in the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2p0wRQs1ouzN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "for sim_out in sim_outs: # for each scene\n",
    "    vis_in = simulation_out_to_visualizer_scene(sim_out, mapAPI)\n",
    "    show(visualize(sim_out.scene_id, vis_in))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of simluation_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
